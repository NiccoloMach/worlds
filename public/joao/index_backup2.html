<!DOCTYPE html>
<html lang="en">
    <head>
        <title>Sound Check</title>
        <meta charset="utf-8">
        <meta property="og:title" content="WebVR Workshop"/>
        <meta property="og:type" content="website"/>
        <meta property="og:image" content="https://worlds.marpi.pl/assets/image.jpg"/>
        <meta name="viewport" content="width=device-width, user-scalable=no, minimum-scale=1.0, maximum-scale=1.0">
        <style>
            body {
                margin: 0px;
                overflow: hidden;
                background-color: #000;
            }
        </style>
    </head>
    <body>


        <script>
            var audio = new Audio();
            audio.src = 'http://api.soundcloud.com/tracks/204082098/stream?client_id=17a992358db64d99e492326797fff3e8';
            audio.controls = true;
            audio.autoplay = true;
            audio.crossOrigin = "anonymous";


            var playMyMusic = function(audio) {
                var self = this;
                var analyser;
                var levelsCount = 16; //should be factor of 512
                var binCount; //512
                var levelBins;

                var audioCtx = new (window.AudioContext || window.webkitAudioContext); // this is because it's not been standardised accross browsers yet.
                analyser = audioCtx.createAnalyser();
                analyser.fftSize = 256; // see - there is that 'fft' thing. 
                var source = audioCtx.createMediaElementSource(audio); // this is where we hook up the <audio> element
                source.connect(analyser);

                analyser.connect(audioCtx.destination);
                binCount = analyser.frequencyBinCount; // = 512
                levelBins = Math.floor(binCount / levelsCount); //number of bins in each level

                freqByteData = new Uint8Array(binCount); 
                timeByteData = new Uint8Array(binCount);

                // var sampleAudioStream = function() {
                //     // This closure is where the magic happens. Because it gets called with setInterval below, it continuously samples the audio data
                //     // and updates the streamData and volume properties. This the SoundCouldAudioSource function can be passed to a visualization routine and 
                //     // continue to give real-time data on the audio stream.
                //     analyser.getByteFrequencyData(self.streamData);
                //     // calculate an overall volume value
                //     var total = 0;
                //     for (var i = 0; i < 80; i++) { // get the volume from the first 80 bins, else it gets too loud with treble
                //         total += self.streamData[i];
                //     }
                //     self.volume = total;
                // };
                // setInterval(sampleAudioStream, 20); // 
                // // public properties and methods
                // this.volume = 0;
                // this.streamData = new Uint8Array(128); // This just means we will have 128 "bins" (always half the analyzer.fftsize value), each containing a number between 0 and 255. 
                // // this.playStream = function(streamUrl) {
                // //     // get the input stream from the audio element
                // //     player.setAttribute('src', streamUrl);
                // //     player.play();
                // // }
            };

            var audioSource = new playMyMusic(audio);

            function update() {
                analyser.getByteFrequencyData(freqByteData);
            }



            var camera, scene, renderer;
            var mobile = false;

            var cubes = []
            var group
            var object
            var verticesOriginal

            var time = 0;

            init();
            setup();
            render();

            function init() {

                // renderer

                renderer = new THREE.WebGLRenderer({antialias: true});
                renderer.setPixelRatio(window.devicePixelRatio);
                renderer.setSize(window.innerWidth, window.innerHeight);
                document.body.appendChild(renderer.domElement);

                // scene

                scene = new THREE.Scene();

                // camera

                camera = new THREE.PerspectiveCamera(100, window.innerWidth / window.innerHeight, .1, 1000);
                camera.position.set(0, 0, 3);
                camera.focalLength = camera.position.distanceTo(scene.position);
                scene.add(camera)

                // controls

                controls = new THREE.OrbitControls(camera);
                controls.autoRotate = true;
                //controls.maxDistance=1

                if (WEBVR.isAvailable() === true) {
                    controls = new THREE.VRControls(camera);
                    controls.standing = false;

                    renderer = new THREE.VREffect(renderer);
                    document.body.appendChild(WEBVR.getButton(renderer));
                }

                // events

                window.addEventListener('deviceorientation', setOrientationControls, true);
                window.addEventListener('resize', onWindowResize, false);

            }

            function setup() {

                var cubeMap = getCubeMap(1)

                /*var texture = new THREE.TextureLoader().load("assets/textures/class.jpg");
                 texture.wrapS = THREE.RepeatWrapping;
                 texture.wrapT = THREE.RepeatWrapping;
                 texture.repeat.set(1, 1);
                 
                 var geometry = new THREE.SphereGeometry(1,25,20);
                 var material = new THREE.MeshBasicMaterial({map:texture, side:THREE.DoubleSide});
                 
                 var object = new THREE.Mesh(geometry, material);
                 object.scale.x=-1;
                 scene.add(object);*/


                // skybox

                var cubeShader = THREE.ShaderLib['cube'];
                cubeShader.uniforms['tCube'].value = cubeMap;

                var skyBoxMaterial = new THREE.ShaderMaterial({
                    fragmentShader: cubeShader.fragmentShader,
                    vertexShader: cubeShader.vertexShader,
                    uniforms: cubeShader.uniforms,
                    depthWrite: false,
                    side: THREE.BackSide
                });

                var skyBox = new THREE.Mesh(new THREE.SphereGeometry(100, 100, 100), skyBoxMaterial);

                scene.add(skyBox);

                // central object

                var geometry = new THREE.IcosahedronGeometry(1, 1);
                verticesOriginal = geometry.clone().vertices;
                var material = new THREE.MeshPhongMaterial({shading: THREE.FlatShading, envMap: cubeMap, wireframe: false});
                object = new THREE.Mesh(geometry, material);
                scene.add(object);

                // light

                var light = new THREE.DirectionalLight(0xffffff);
                light.position.set(-1, 1.5, 0.5);
                //var light = new THREE.PointLight(0xFFFFFF,1,10)
                //light.position.x=-1
                camera.add(light);

                //var ambient = new THREE.AmbientLight(0x666666)
                //scene.add(ambient)
            }

            function render() {
                requestAnimationFrame(render);

                controls.update();

                time += .01


                object.rotation.x += .01
                object.rotation.y += .01

                var v = object.geometry.vertices
                for(bin = 0; bin < audioSource.streamData.length; bin ++) {
                    var val = audioSource.streamData[bin] / 100;

                    for (var i = 0; i < v.length; i++) {
                        if (Math.random() < .01) {
                            TweenMax.to(v[i], .1, {
                                x: verticesOriginal[i].x * (val),
                                y: verticesOriginal[i].y * (val),
                                z: verticesOriginal[i].z * (val)
                            })
                        } else {
                            TweenMax.to(v[i], 1, {
                                x: verticesOriginal[i].x,
                                y: verticesOriginal[i].y,
                                z: verticesOriginal[i].z
                            })
                        }
                        //console.log(v)
                    }
                    object.geometry.verticesNeedUpdate = true;
                }

                if (mobile) {
                    camera.position.set(0, 0, 0)
                    camera.translateZ(5);
                }
                renderer.render(scene, camera);

            }

        </script>
    </body>
</html>